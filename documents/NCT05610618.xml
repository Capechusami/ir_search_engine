<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on May 09, 2023</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT05610618</url>
  </required_header>
  <id_info>
    <org_study_id>38RC22.0207</org_study_id>
    <secondary_id>2022-A01418-35</secondary_id>
    <nct_id>NCT05610618</nct_id>
  </id_info>
  <brief_title>Study of Brain Activity Underlying Predictive Mechanisms During the Perception of Visual Scenes</brief_title>
  <acronym>PREPER</acronym>
  <official_title>Etude de l'activité cérébrale Sous-jacente Aux mécanismes prédictifs Lors de la Perception de scènes Visuelles</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University Hospital, Grenoble</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>University Hospital, Grenoble</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      This study aims to clarify the mechanisms by which the predictions we have about our visual&#xD;
      environment influence the processing of expected or unexpected visual stimuli at the cerebral&#xD;
      level.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Current models of visual perception agree that perception is a proactive process. According&#xD;
      to these models, perception of the visual environment would allow to continuously generate&#xD;
      expectations or &quot;predictions&quot; about the likely characteristics of a visual scene, which would&#xD;
      facilitate their processing and visual recognition. At the neurobiological level, these&#xD;
      models postulate that visual perception is the result of a permanent exchange between&#xD;
      prediction signals (i.e., predicted characteristics of the visual stimulus) and prediction&#xD;
      error signals (i.e., unprovevised characteristics of the stimulus to update predictions)&#xD;
      between consecutive levels of the hierarchy of cortical visual areas. However, the&#xD;
      neurophysiological correlates of these mechanisms remain debated. The results of some work&#xD;
      suggest that the prediction signals generated by high-level cortical areas would make it&#xD;
      possible to pre-process the predicted characteristics of a stimulus within lower-level areas,&#xD;
      by inhibiting the activity of neurons dedicated to their processing. Conversely, other work&#xD;
      postulates that the prediction signals generated by high-level areas would increase the&#xD;
      sensitivity of neurons encoding expected characteristics while inhibiting the response of&#xD;
      neurons encoding unexpected features in lower-level areas. Accordingly, brain activity in&#xD;
      these regions would rather reflect the processing of expected features of visual stimuli. It&#xD;
      has also been proposed that these two mechanisms coexist but that they intervene alternately&#xD;
      during the temporal course of brain processing and depending on the quality of the visual&#xD;
      signal. However, this hypothesis has never been systematically tested. The objective of the&#xD;
      project is to improve fundamental knowledge about the mechanisms of visual perception by&#xD;
      studying at the cerebral level how predictions about the visual environment influence its&#xD;
      visual perception. Specifically, investigators will use electroencephalography (EEG)&#xD;
      recordings from healthy volunteer participants to measure how brain activity related to&#xD;
      visual processing of images of objects and scenes is modulated by their expected or&#xD;
      unexpected character, taking into account the temporal course of brain processing and&#xD;
      considering the quality of visual signals.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">March 20, 2023</start_date>
  <completion_date type="Anticipated">March 2025</completion_date>
  <primary_completion_date type="Anticipated">March 2025</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Performance (% of correct classification) of a support vector machine algorithm in classifying the category of objects and scenes based on electroencephalography signals evoked by the visual perception of expected and unexpected objects and scenes</measure>
    <time_frame>Through study completion, an average of 1.5 year</time_frame>
    <description>We will use EEG data acquired while participants look at neutral objects and scenes of different categories to train a classifier in decoding the category of these objects and scenes. This classifier will then be tested using EEG data acquired while participants look at novel expected and unexpected objects and scenes. We will record the % accuracy of the classifier in this test phase.</description>
  </primary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">80</enrollment>
  <condition>Physiological Reactivity to Cues</condition>
  <arm_group>
    <arm_group_label>Healthy adults</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>A single group of healthy adults will undergo all experimental conditions (within subject design)</description>
  </arm_group>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Visual stimulation</intervention_name>
    <description>Participants will be displayed with photographs of scenes and objects which predictability and sharpness will be manipulated</description>
    <arm_group_label>Healthy adults</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          -  Participants between 18 and 35 years old&#xD;
&#xD;
          -  Normal or corrected-to-normal visual acuity&#xD;
&#xD;
          -  Ability to consent or oppose to the research&#xD;
&#xD;
          -  No opposition to the research&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
          -  Important visual impairments&#xD;
&#xD;
          -  Neuropsychiatric pathology&#xD;
&#xD;
          -  Use of drug or medication with neurocognitive effects&#xD;
&#xD;
          -  Minors, or persons under psychiatric care, or protected persons&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>35 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Laurent VERCUEIL</last_name>
    <role>Principal Investigator</role>
    <affiliation>Grenoble Alpes University Hospital</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Louise KAUFFMANN</last_name>
    <phone>+33 (0)4 76 74 81 35</phone>
    <email>louise.kauffmann@univ-grenoble-alpes.fr</email>
  </overall_contact>
  <location>
    <facility>
      <name>Louise KAUFFMANN</name>
      <address>
        <city>Grenoble</city>
        <state>Grenoble Cedex 9</state>
        <zip>38043</zip>
        <country>France</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Louise KAUFFMANN</last_name>
      <phone>+33476748135</phone>
      <email>louise.kauffmann@univ-grenoble-alpes.fr</email>
    </contact>
    <investigator>
      <last_name>Laurent VERCUEIL</last_name>
      <role>Principal Investigator</role>
    </investigator>
  </location>
  <location_countries>
    <country>France</country>
  </location_countries>
  <verification_date>March 2023</verification_date>
  <study_first_submitted>September 12, 2022</study_first_submitted>
  <study_first_submitted_qc>November 8, 2022</study_first_submitted_qc>
  <study_first_posted type="Actual">November 9, 2022</study_first_posted>
  <last_update_submitted>March 23, 2023</last_update_submitted>
  <last_update_submitted_qc>March 23, 2023</last_update_submitted_qc>
  <last_update_posted type="Actual">March 24, 2023</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

